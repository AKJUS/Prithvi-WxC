{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrithviWxC\n",
    "\n",
    "This notebook will walk through how to construct the model, loading the weights,\n",
    "building the dataset, and use the model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PrithviWxC.merra2 import (\n",
    "    Merra2Dataset,\n",
    "    input_scalers,\n",
    "    output_scalers,\n",
    "    preproc,\n",
    "    static_input_scalers,\n",
    ")\n",
    "from PrithviWxC.model import PrithviWxC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now configuration the backends and torch states, including setting the seeds\n",
    "for the RNGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.enable_onednn_fusion(True)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using device: {torch.cuda.get_device_name()}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set the device to use for inference. The model has ~2.3billion\n",
    "parameters, so requires some resonable compuational resouces, but it is possible\n",
    "to run this on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "### Variables and times\n",
    "\n",
    "With the environment ready to go, we now need to set up the task. The core model\n",
    "expects a fixed set of variables from the MERRA-2 dataset, which are prescribed\n",
    "below. The variables are comprised of surface variables, surface static\n",
    "variables, and variables at various vertical levels within the atmosphere. More\n",
    "details on the MERRA-2 dataset can be found\n",
    "[here](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/). \n",
    "\n",
    "The MERRA2 dataset includes data at longtitudes of $-180^\\circ$ and\n",
    "$+180^\\circ$, this represents repeated data and so we set a padding variable\n",
    "to remove this.\n",
    "\n",
    "The input to the core model are these variables at two times, the time\n",
    "difference in hours between these samples is passed to the model and is set in\n",
    "the `input_time` variable.\n",
    "\n",
    "The task of the model is, given the input data, to predict the fixed set of\n",
    "variables at a target time. The target time is set relative to input times, ie\n",
    "if the inputs are 0900 and 1200, giving `input_time=-3`, then a `lead_time=6`\n",
    "would give a target time of 1800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_vars = [\n",
    "    \"EFLUX\",\n",
    "    \"GWETROOT\",\n",
    "    \"HFLUX\",\n",
    "    \"LAI\",\n",
    "    \"LWGAB\",\n",
    "    \"LWGEM\",\n",
    "    \"LWTUP\",\n",
    "    \"PS\",\n",
    "    \"QV2M\",\n",
    "    \"SLP\",\n",
    "    \"SWGNT\",\n",
    "    \"SWTNT\",\n",
    "    \"T2M\",\n",
    "    \"TQI\",\n",
    "    \"TQL\",\n",
    "    \"TQV\",\n",
    "    \"TS\",\n",
    "    \"U10M\",\n",
    "    \"V10M\",\n",
    "    \"Z0M\",\n",
    "]\n",
    "static_surface_vars = [\"FRACI\", \"FRLAND\", \"FROCEAN\", \"PHIS\"]\n",
    "vertical_vars = [\"CLOUD\", \"H\", \"OMEGA\", \"PL\", \"QI\", \"QL\", \"QV\", \"T\", \"U\", \"V\"]\n",
    "levels = [\n",
    "    34.0,\n",
    "    39.0,\n",
    "    41.0,\n",
    "    43.0,\n",
    "    44.0,\n",
    "    45.0,\n",
    "    48.0,\n",
    "    51.0,\n",
    "    53.0,\n",
    "    56.0,\n",
    "    63.0,\n",
    "    68.0,\n",
    "    71.0,\n",
    "    72.0,\n",
    "]\n",
    "padding = {\"level\": [0, 0], \"lat\": [0, -1], \"lon\": [0, 0]}\n",
    "\n",
    "lead_times = [6]  # This varibale can be change to change the task\n",
    "input_times = [-6]  # This varibale can be change to change the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data file\n",
    "MERRA-2 data is available from 1980 to the present day, at 3 hours temporal\n",
    "resolution. The dataloader we have provided expects the surface data and\n",
    "vertical data to be saved in seperate files, and when provided with the\n",
    "directories, will serach for the relavent data that falls within the provided\n",
    "time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = (\"2016-02-01T00:00:00\", \"2016-02-06T23:59:59\")\n",
    "\n",
    "surf_dir = Path(\"path/to/merra-2\")\n",
    "vert_dir = Path(\"path/to/merra-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climatology\n",
    "The  PrithviWxC model was trained to calculate the output by producing a\n",
    "perturbation to the climatology at the target time. This mode of operation is\n",
    "set via the `residual=climate` option. This was chosen as climatology is\n",
    "typically a strong proir for long-range prediciton. When using the\n",
    "`residual=climate` option, we have to provide the dataloader with the path of\n",
    "the climatology data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_clim_dir = Path(\"path/to/climatology\")\n",
    "vert_clim_dir = Path(\"path/to/climatology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_in_scal_path = Path(\"path/to/musigma_surface.nc\")\n",
    "vert_in_scal_path = Path(\"path/to/musigma_vertical.nc\")\n",
    "surf_out_scal_path = Path(\"path/to/anomaly_variance_surface.nc\")\n",
    "vert_out_scal_path = Path(\"path/to/anomaly_variance_vertical.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = Path(\"path/to/pretrained/step_400.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postion encoding\n",
    "Possition data is included in the data passed to the model, as this allows the\n",
    "attention mechanism to determine data locality rather than explicit or implicit\n",
    "data connections. The postion data is encoded in the model with two possible\n",
    "options, `fourier` or `absolute`. As these require different treatmment within\n",
    "the data loader, it is set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = \"fourier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset init\n",
    "We can now instantiate the MERRA2 Dataset class provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Merra2Dataset(\n",
    "    time_range=time_range,\n",
    "    lead_times=lead_times,\n",
    "    data_path_surface=surf_dir,\n",
    "    data_path_vertical=vert_dir,\n",
    "    climatology_path_surface=surf_clim_dir,\n",
    "    climatology_path_vertical=vert_clim_dir,\n",
    "    surface_vars=surface_vars,\n",
    "    static_surface_vars=static_surface_vars,\n",
    "    vertical_vars=vertical_vars,\n",
    "    levels=levels,\n",
    "    positional_encoding=positional_encoding,\n",
    "    input_times=input_times,\n",
    ")\n",
    "assert len(dataset) > 0, \"There doesn't seem to be any valid data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "We are now ready to build the mdoel.\n",
    "### Scalers\n",
    "As additional static parameters, the model takes the mean and varience values\n",
    "of the input varaibles and the varience values of the target difference, ie the\n",
    "varience between climatology and instaneous variables. We have provided\n",
    "datafiles containing these and here we load in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mu, in_sig = input_scalers(\n",
    "    surface_vars,\n",
    "    vertical_vars,\n",
    "    levels,\n",
    "    surf_in_scal_path,\n",
    "    vert_in_scal_path,\n",
    ")\n",
    "\n",
    "output_sig = output_scalers(\n",
    "    surface_vars,\n",
    "    vertical_vars,\n",
    "    levels,\n",
    "    surf_out_scal_path,\n",
    "    vert_out_scal_path,\n",
    ")\n",
    "\n",
    "static_mu, static_sig = static_input_scalers(\n",
    "    surf_in_scal_path,\n",
    "    static_surface_vars,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task and additional configs\n",
    "As we stated above, the pretext task for the PrithviWxC model was predicting the\n",
    "variable set at the requested lead time by calculating the delta relative to the\n",
    "climatology at that time. This mode of operation is set via the `residual` flag.\n",
    "Additional residual options are implemented in hte model, however the core model\n",
    "weights were not trained with in these modes of operation.\n",
    "\n",
    "Addtionally, for training and evaluation it is possible to mask tokens in the\n",
    "model. The masking occuring after tokenisation, prior to the encoder layers.\n",
    "The model uses multi-axis attention, with data broken down into a hierachy of\n",
    "local and global patches. Consequently, masking can be configured to mask either\n",
    "small local patches or larger global patches. This is set via the `masking_mode`\n",
    "flag. It is possible to set `masking_mode=both`, this doesn't mix the modes, but\n",
    "rather both modes can be used and swapped between, primarily for training. For\n",
    "this demonstration we will set the masking ratio to show the reconstrction\n",
    "abilities of the model.\n",
    "\n",
    "Finally, we can set up shifting. Primarily in the decioder, this enable\n",
    "alternate shifting of the attention windows, similar to the SWIN model. This\n",
    "option requires the number of decoder blocks to be even, and cannot be used in\n",
    "the encoder when masking is also used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = \"climate\"\n",
    "masking_mode = \"local\"\n",
    "decoder_shifting = True\n",
    "masking_ratio = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model init\n",
    "We now have all the peices to build the model. If you are using the pretrained\n",
    "weights, then a number of the model hyperparameters are predetermined and\n",
    "included below. With this configuration, the model will have approximately\n",
    "2.3billion parameters. Therefore, if you want to train the fully unfrozen model,\n",
    "you will likely need to use a model distribution approach, such as fully shared\n",
    "data parallelism (FSDP). To further reduce the memory usage of the model,\n",
    "when gradients are required, there two varaiables --- `checkpoint_encoder` and\n",
    "`checkpoint_decoder` --- which enable activation checkpointing of desired\n",
    "transformer layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PrithviWxC(\n",
    "    in_channels=160,\n",
    "    input_size_time=2,\n",
    "    in_channels_static=8,\n",
    "    input_scalers_mu=in_mu,\n",
    "    input_scalers_sigma=in_sig,\n",
    "    input_scalers_epsilon=0.0,\n",
    "    static_input_scalers_mu=static_mu,\n",
    "    static_input_scalers_sigma=static_sig,\n",
    "    static_input_scalers_epsilon=0.0,\n",
    "    output_scalers=output_sig**0.5,\n",
    "    n_lats_px=360,\n",
    "    n_lons_px=576,\n",
    "    patch_size_px=[2, 2],\n",
    "    mask_unit_size_px=[30, 32],\n",
    "    mask_ratio_inputs=masking_ratio,\n",
    "    embed_dim=2560,\n",
    "    n_blocks_encoder=12,\n",
    "    n_blocks_decoder=2,\n",
    "    mlp_multiplier=4,\n",
    "    n_heads=16,\n",
    "    dropout=0.0,\n",
    "    drop_path=0.0,\n",
    "    parameter_dropout=0.0,\n",
    "    residual=residual,\n",
    "    masking_mode=masking_mode,\n",
    "    decoder_shifting=decoder_shifting,\n",
    "    positional_encoding=positional_encoding,\n",
    "    checkpoint_encoder=[],\n",
    "    checkpoint_decoder=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights\n",
    "We have provided unshared pretrained weights for the model, which can now be\n",
    "loaded and model can then be transfered to the requested device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(weights_path, weights_only=False)\n",
    "if \"model_state\" in state_dict:\n",
    "    state_dict = state_dict[\"model_state\"]\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "if (hasattr(model, \"device\") and model.device != device) or not hasattr(\n",
    "    model, \"device\"\n",
    "):\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "We are now ready to performace inference on the model. The data returned from\n",
    "the dataset class requires some additional preprocessing, so after polling the\n",
    "dataset we run the data through the `preproc` function.\n",
    "\n",
    "To retreive the masking, we can save the torch RNG state and use it to recover\n",
    "the masking later. Finally, we can run the model in evaluation mode and without\n",
    "generating the gradient graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(dataset))\n",
    "for k, v in data.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        data[k] = v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = preproc([data], padding)\n",
    "\n",
    "rng_state_1 = torch.get_rng_state()\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    out = model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m = out[0, 12].cpu().numpy()\n",
    "\n",
    "lat = np.linspace(-90, 90, out.shape[-2])\n",
    "lon = np.linspace(-180, 180, out.shape[-1])\n",
    "X, Y = np.meshgrid(lon, lat)\n",
    "\n",
    "plt.contourf(X, Y, t2m, 100)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
